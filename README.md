# NoiseAttack
This repository contains code for generating stochastic input noises (single and compound) and for running in-domain attacks.

# Description
This repository provides code for generating a wide range of stochastic input noises—including both single-source and compound variants—used in the study: “Should All Noises Be Treated Equally? Impact of Input Noise Variability on Neural Network Robustness.”

It also includes scripts for implementing in-domain noise-based attacks described in: “Noise Attacks: Enhancing the Robustness of Neural Networks through In-domain Attacks.”

Use this code to:

Generate and apply structured, unstructured, and compound noise patterns to images.

Reproduce in-domain adversarial attacks under controlled stochastic noise settings.

Benchmark model robustness under diverse input perturbation regimes.
